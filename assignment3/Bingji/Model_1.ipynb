{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('TextMining': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0f9ff2c600c59c82c9e3581726354ed68de8a0719f3400046597b86abf94d3c8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Start a Spark session"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\") \\\n",
    "                    .appName('Assignment 3 WBJ') \\\n",
    "                    .getOrCreate()\n",
    "sc = SparkContext.getOrCreate( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbe4b33b750>"
      ],
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.45.41.140:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[2]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>SparkByExamples.com</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "source": [
    "### Data reading and cleaning "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We only care about 6 specific tags and corresponding texts, and missing data should be removed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data  = spark.read.csv(\"/Users/mac/Desktop/KU\\ Leuven/Advanced\\ Analytics\\ in\\ a\\ Big\\ Data\\ World/Assignment3/dfPD.csv\", header=True, inferSchema=True )\n",
    "\n",
    "# clean and split data\n",
    "clean_data = data.filter((data.tweet_text != \"None\") & (data.tweet_id != \"None\")& (data.label != \"None\") & (data.label.isin([\"#vaccine\", \"#stopasianhate\", \"#covid\", \"#china\", \"#inflation\", \"#biden\"])))"
   ]
  },
  {
   "source": [
    "There are many Emojis and blocked contents in \"tweet_text\" column. By using regular expression, we are able to extract texts and remove noise. Since the dataframe in pyspark is treated as tuple which can't be modified, we have to convert pyspark dataframe to pandas dataframe first."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "new_data = clean_data.toPandas()\n",
    "for row in range(len(new_data[\"tweet_text\"])):\n",
    "    # new_data[\"tweet_text\"][row] = \" \".join(re.findall(r\"[a-zA-Z,;.':\\\\]+\", new_data[\"tweet_text\"][row])) \n",
    "    new_data[\"tweet_text\"][row] = \" \".join(re.findall(r\"[a-zA-Z']+\", new_data[\"tweet_text\"][row])).lower() \n",
    "\n",
    "clean_data = spark.createDataFrame(new_data) "
   ]
  },
  {
   "source": [
    "Check if the cleaning work is done "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+-----+\n|         label|count|\n+--------------+-----+\n|        #biden| 1319|\n|      #vaccine| 2900|\n|        #china| 2366|\n|        #covid| 2492|\n|#stopasianhate|  730|\n|    #inflation|  259|\n+--------------+-----+\n\nroot\n |-- label: string (nullable = true)\n |-- tweet_id: string (nullable = true)\n |-- tweet_text: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "clean_data.groupby(\"label\").count().show()\n",
    "clean_data.printSchema()\n",
    "(trainingData, testData) = clean_data.randomSplit([0.7, 0.3], seed = 100)\n",
    "# clean_data.select('label').limit(2).collect()\n",
    "# (trainingData.count(), testData.count())"
   ]
  },
  {
   "source": [
    "Import necessary packages and functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StopWordsRemover, IDF, StringIndexer, RegexTokenizer\n",
    "from pyspark.ml.feature import VectorAssembler, Word2Vec\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select(\"label\", \"tweet_text\")\n",
    "clean_data = clean_data.withColumnRenamed('label', 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(tweet_text='Today I learned that the origin of the word vaccine is tied to the latin word cow which is vacca The reason for this is due to the first smallpox vaccine using the milder cowpox virus to innoculate people'),\n",
       " Row(tweet_text='Insights into webinar on Reigniting Manufacturing Growth through MSME Development Electrical and Electronic sector'),\n",
       " Row(tweet_text='tests for pray'),\n",
       " Row(tweet_text=\"COVIDLandia Wisdom Loathing and Lots of Netflix inside America's Potemkin Government Book\"),\n",
       " Row(tweet_text='Pennsylvania pauses use of Johnson amp Johnson vaccine'),\n",
       " Row(tweet_text=\"Did you catch us on BBCOxford last night Don't worry you can catch it again here https t co sWfa fmzw and catch Tracy talking all about our fab work with having your vaccination\"),\n",
       " Row(tweet_text='Saturday Sunday Two Days Lockdown in Gandhidham Adipur'),\n",
       " Row(tweet_text='What is a live attenuated Learn more about the s used to treat diseases including and https t co QvkbpyMpT'),\n",
       " Row(tweet_text=\"If you count in the that according to International Law has to supply to Israel's would slip significantly but it is always nice to test the 'herd immunity' with live participants locked in to an outdoor jail https t co Dd x oTnAy\"),\n",
       " Row(tweet_text='Many Incidences of in post patients being reported by my Oral amp Maxillofacial surgeon colleagues leading to Partial or total removal of upper jaw')]"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "clean_data.select('tweet_text').limit(10).collect()"
   ]
  },
  {
   "source": [
    "Below is a simple pipeline without any feature selection work"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_spam_to_numeric = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol = 'tweet_text', outputCol = 'token_text')\n",
    "stop_remove = StopWordsRemover(inputCol = 'token_text', outputCol = 'stop_token')\n",
    "count_vec = CountVectorizer(inputCol = 'stop_token', outputCol = 'c_vec')\n",
    "idf = IDF(inputCol = 'c_vec', outputCol = 'tf_idf')\n",
    "clean_up = VectorAssembler(inputCols = ['tf_idf'], outputCol = 'features')\n",
    "\n",
    "pipeline = Pipeline(stages=[ham_spam_to_numeric, tokenizer, stop_remove, count_vec, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "A pipeline with ChiSqSelector and increase the accuracy by more than 10%. Parameter \"numTopFeatures\" stands for how many features you wanto select."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_spam_to_numeric = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol = 'tweet_text', outputCol = 'token_text')\n",
    "stop_remove = StopWordsRemover(inputCol = 'token_text', outputCol = 'stop_token')\n",
    "count_vec = CountVectorizer(inputCol = 'stop_token', outputCol = 'c_vec')\n",
    "idf = IDF(inputCol = 'c_vec', outputCol = 'tf_idf')\n",
    "clean_up = VectorAssembler(inputCols = ['tf_idf'], outputCol = 'raw_features')\n",
    "final_data = ChiSqSelector(numTopFeatures = 5500, featuresCol=\"raw_features\",\n",
    "                         outputCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "pipeline = Pipeline(stages=[ham_spam_to_numeric, tokenizer, stop_remove, count_vec, idf, clean_up, final_data, nb])\n"
   ]
  },
  {
   "source": [
    "A pipeline with UnivariateFeatureSelector. Model will select the feactures with threshold above the parameter \"setSelectionThreshold\". If properly selected, it produces similar results as ChiSqSelector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "ham_spam_to_numeric = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol = 'tweet_text', outputCol = 'token_text')\n",
    "stop_remove = StopWordsRemover(inputCol = 'token_text', outputCol = 'stop_token')\n",
    "count_vec = CountVectorizer(inputCol = 'stop_token', outputCol = 'c_vec')\n",
    "idf = IDF(inputCol = 'c_vec', outputCol = 'tf_idf')\n",
    "clean_up = VectorAssembler(inputCols = ['tf_idf'], outputCol = 'raw_features')\n",
    "final_data = UnivariateFeatureSelector(featuresCol=\"raw_features\",\n",
    "                         outputCol=\"features\", labelCol=\"label\",selectionMode=\"fdr\").setFeatureType(\"categorical\").setLabelType(\"categorical\").setSelectionThreshold(0.5)\n",
    "\n",
    "pipeline = Pipeline(stages=[ham_spam_to_numeric, tokenizer, stop_remove, count_vec, idf, clean_up, final_data])"
   ]
  },
  {
   "source": [
    "Fit the data based on the pipeline you select and make sure you only run one pipeline above.\n",
    "You may change the proportion of trainingData and testData."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- token_text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- stop_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- c_vec: vector (nullable = true)\n",
      " |-- tf_idf: vector (nullable = true)\n",
      " |-- raw_features: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "+--------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|   class|          tweet_text|label|          token_text|          stop_token|               c_vec|              tf_idf|        raw_features|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|#vaccine|today i learned t...|  0.0|[today, i, learne...|[today, learned, ...|(23850,[4,5,14,17...|(23850,[4,5,14,17...|(23850,[4,5,14,17...|(5500,[4,5,14,17,...|[-344.30430520380...|[1.0,2.2821576419...|       0.0|\n",
      "|  #covid|insights into web...|  1.0|[insights, into, ...|[insights, webina...|(23850,[283,529,8...|(23850,[283,529,8...|(23850,[283,529,8...|(5500,[216,397,10...|[-154.44841798790...|[8.87001435792908...|       2.0|\n",
      "|  #covid|      tests for pray|  1.0|  [tests, for, pray]|       [tests, pray]|(23850,[635,1055]...|(23850,[635,1055]...|(23850,[635,1055]...|(5500,[462,735],[...|[-101.00484918591...|[2.23181763104789...|       1.0|\n",
      "|  #covid|covidlandia wisdo...|  1.0|[covidlandia, wis...|[covidlandia, wis...|(23850,[58,423,10...|(23850,[58,423,10...|(23850,[58,423,10...|(5500,[49,320,100...|[-229.59961033625...|[2.91257705640953...|       1.0|\n",
      "|#vaccine|pennsylvania paus...|  0.0|[pennsylvania, pa...|[pennsylvania, pa...|(23850,[2,4,90,17...|(23850,[2,4,90,17...|(23850,[2,4,90,17...|(5500,[2,4,136],[...|[-85.748564281648...|[0.99999999973231...|       0.0|\n",
      "+--------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(5500,[4,5,14,17,...|\n",
      "|  1.0|(5500,[216,397,10...|\n",
      "|  1.0|(5500,[462,735],[...|\n",
      "|  1.0|(5500,[49,320,100...|\n",
      "|  0.0|(5500,[2,4,136],[...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaner = pipeline.fit(clean_data)\n",
    "clean_df = cleaner.transform(clean_data)\n",
    "clean_df.printSchema()\n",
    "clean_df.show(5)\n",
    "clean_df = clean_df.select('label', 'features')\n",
    "# clean_df = clean_df.withColumnRenamed('class', 'features')\n",
    "clean_df.show(5)\n",
    "(trainingData, testData) = clean_df.randomSplit([0.7, 0.3], seed = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- class: string (nullable = true)\n |-- tweet_text: string (nullable = true)\n\nroot\n |-- label: double (nullable = false)\n |-- features: vector (nullable = true)\n\nroot\n |-- label: double (nullable = false)\n |-- features: vector (nullable = true)\n\nroot\n |-- label: double (nullable = false)\n |-- features: vector (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "clean_data.printSchema()\n",
    "clean_df.printSchema()\n",
    "trainingData.printSchema()\n",
    "testData.printSchema()"
   ]
  },
  {
   "source": [
    "Train a NaiveBayes model and compare its results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+------------+--------------------+--------------------+----------+\n",
      "|label|    features|       rawPrediction|         probability|prediction|\n",
      "+-----+------------+--------------------+--------------------+----------+\n",
      "|  0.0|(5500,[],[])|[-1.2454099941901...|[0.28782287822878...|       0.0|\n",
      "|  0.0|(5500,[],[])|[-1.2454099941901...|[0.28782287822878...|       0.0|\n",
      "|  0.0|(5500,[],[])|[-1.2454099941901...|[0.28782287822878...|       0.0|\n",
      "+-----+------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Test Accuracy: 0.6354923992068737\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes()\n",
    "tag_classifier = nb.fit(trainingData)\n",
    "predictions = tag_classifier.transform(testData)\n",
    "predictions.show(3)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "print(\"Test Accuracy: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})))"
   ]
  },
  {
   "source": [
    "DON NOT run the pipeline above, and instead run the following codes right after the data cleaning cell and before the data fitting cell.\n",
    "\n",
    "If you want to include cross validation, run the codes below. \n",
    "If you want reliable results, go for TrainValidationSplit, which fits the data multiple times."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 0.5588235294117647\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "ham_spam_to_numeric = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol = 'tweet_text', outputCol = 'token_text')\n",
    "stop_remove = StopWordsRemover(inputCol = 'token_text', outputCol = 'stop_token')\n",
    "count_vec = CountVectorizer(inputCol = 'stop_token', outputCol = 'c_vec')\n",
    "idf = IDF(inputCol = 'c_vec', outputCol = 'tf_idf')\n",
    "clean_up = VectorAssembler(inputCols = ['tf_idf'], outputCol = 'raw_features')\n",
    "final_data = ChiSqSelector(featuresCol=\"raw_features\",\n",
    "                          outputCol=\"features\", labelCol=\"label\")\n",
    "nb = NaiveBayes()\n",
    "\n",
    "pipeline = Pipeline(stages=[ham_spam_to_numeric, tokenizer, stop_remove, count_vec, idf, clean_up, final_data, nb])\n",
    "\n",
    "\n",
    "(trainingData, testData) = clean_data.randomSplit([0.7, 0.3], seed = 200)\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(final_data.numTopFeatures, list(range(4000,6000,100))) \\\n",
    "    .build()\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=MulticlassClassificationEvaluator(),\n",
    "                           trainRatio=0.7)\n",
    "\n",
    "tag_classifier = tvs.fit(trainingData)\n",
    "predictions = tag_classifier.transform(testData)\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "print(\"Test Accuracy: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})))"
   ]
  },
  {
   "source": [
    "Train the random forest model.\n",
    "\n",
    "If you run the cross validation cell above, remember to rerun the pipeline and fit the data, otherwise you will use the raw data WITHOUT ANY pre-processing work."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "rf_mode = rf.fit(trainingData)\n",
    "\n",
    "predictions_rf = rf_mode.transform(testData)\n",
    "evaluator_rf = MulticlassClassificationEvaluator()\n",
    "print(\"Test Accuracy: \" + str(evaluator_rf.evaluate(predictions_rf, {evaluator_rf.metricName: \"accuracy\"})))"
   ]
  },
  {
   "source": [
    "Train the one-vs-rest model\n",
    "\n",
    "If you run the cross validation cell above, remember to rerun the pipeline and fit the data, otherwise you will use the raw data WITHOUT ANY pre-processing work."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "lr = LogisticRegression(maxIter=20, tol=1E-6, fitIntercept=True)\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "tag_classifier_ovr = ovr.fit(trainingData)\n",
    "\n",
    "predictions_ovr = tag_classifier_ovr.transform(testData)\n",
    "evaluator_ovr = MulticlassClassificationEvaluator()\n",
    "print(\"Test Accuracy: \" + str(evaluator_ovr.evaluate(predictions_ovr, {evaluator_ovr.metricName: \"accuracy\"})))"
   ]
  },
  {
   "source": [
    "Train the multi-layer perceptron model, and make sure the input dimension is equal to the number of features. You can do this manually or just put the feature output size inside. Be carefully about the overstack problem.\n",
    "\n",
    "If you run the cross validation cell above, remember to rerun the pipeline and fit the data, otherwise you will use the raw data WITHOUT ANY pre-processing work."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 5500 (features), two intermediate of size 100 and 50\n",
    "# and output of size 6 (classes)\n",
    "\n",
    "layers = [5500, 100, 50, 6]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=200, layers=layers, blockSize=64, seed=1234)\n",
    "mlp = trainer.fit(trainingData)\n",
    "\n",
    "predictions_mlp = mlp.transform(testData)\n",
    "evaluator_mlp = MulticlassClassificationEvaluator()\n",
    "print(\"Test Accuracy: \" + str(evaluator_mlp.evaluate(predictions_mlp, {evaluator_mlp.metricName: \"accuracy\"})))"
   ]
  },
  {
   "source": [
    "A pipeline using HashingTF.\n",
    "\n",
    "Can have a try."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "\n",
    "ham_spam_to_numeric = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol = 'tweet_text', outputCol = 'token_text')\n",
    "stop_remove = StopWordsRemover(inputCol = 'token_text', outputCol = 'stop_token')\n",
    "hashingTF = HashingTF(inputCol=\"stop_token\", outputCol=\"rawFeatures\", numFeatures= 8000)\n",
    "idf = IDF(inputCol = 'rawFeatures', outputCol = 'tf_idf')\n",
    "clean_up = VectorAssembler(inputCols = ['tf_idf'], outputCol = 'features')\n",
    "\n",
    "pipeline = Pipeline(stages=[ham_spam_to_numeric, tokenizer, stop_remove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}